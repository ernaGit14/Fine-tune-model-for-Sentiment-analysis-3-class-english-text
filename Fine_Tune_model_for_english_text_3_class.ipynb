{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcU53Pc5UyhVaQsi+b/sAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ernaGit14/Fine-tune-model-for-Sentiment-analysis-3-class-english-text/blob/main/Fine_Tune_model_for_english_text_3_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qu0gMPxQ2CMi"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets scikit-learn accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# 1) Load CSV\n",
        "df = pd.read_csv(\"data_comment with label.csv\", sep=';')\n",
        "\n",
        "# 2) Map string labels to ints\n",
        "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "df[\"label_id\"] = df[\"label\"].map(label2id)\n",
        "\n",
        "# 3) Split train / test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label_id\"], random_state=42)\n",
        "\n",
        "# 4) Convert to HuggingFace Dataset\n",
        "train_ds = Dataset.from_pandas(train_df[[\"text\", \"label_id\"]])\n",
        "test_ds = Dataset.from_pandas(test_df[[\"text\", \"label_id\"]])\n",
        "\n",
        "datasets = DatasetDict({\n",
        "    \"train\": train_ds,\n",
        "    \"test\": test_ds\n",
        "})"
      ],
      "metadata": {
        "id": "-k0YzrKT2M1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"j-hartmann/sentiment-roberta-large-english-3-classes\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xCyCDRWo3HQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ade3800"
      },
      "source": [
        "def tokenize_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_datasets = datasets.map(tokenize_fn, batched=True)\n",
        "\n",
        "# Trainer expects column \"labels\"\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label_id\", \"labels\")\n",
        "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20c85413"
      },
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "241c748e"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./sentiment-roberta-finetuned\",\n",
        "    eval_strategy=\"epoch\", # Changed from evaluation_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\" # Explicitly disable reporting to experiment trackers like wandb\n",
        ")\n",
        "\n",
        "# Instantiate DataCollatorWithPadding to handle dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    # Replaced 'tokenizer=tokenizer' with 'data_collator=data_collator'\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "U5YTCB7u5gRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "vV1SLWpU4plt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "lwHvm0j54i-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./sentiment-roberta-finetuned\")\n",
        "tokenizer.save_pretrained(\"./sentiment-roberta-finetuned\")\n"
      ],
      "metadata": {
        "id": "XXvep4wwHz0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to use new model, fine tune model result\n"
      ],
      "metadata": {
        "id": "P8-aNNZ6NeiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "clf = pipeline( #clf is model classifier\n",
        "    \"text-classification\",\n",
        "    model=\"./sentiment-roberta-finetuned\",\n",
        "    tokenizer=\"./sentiment-roberta-finetuned\",\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "print(clf(\"The product is amazing, I really love it!\"))\n"
      ],
      "metadata": {
        "id": "rdPOQD4NIboO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read new data from data_comment.csv and save it in dataframe"
      ],
      "metadata": {
        "id": "MOk-uAd6NxL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv(\"data_comment.csv\", sep=';')\n",
        "text_column = \"comment\" # define which coloum as the dataText"
      ],
      "metadata": {
        "id": "azgVNxE3KipM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IpqCcgEAOBvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if text_column not in df_data.columns:\n",
        "    raise ValueError(f\"Comment coloum '{text_column}' is not found in your CSV file. List of data coloum : {list(df.columns)}\")\n",
        "\n",
        "texts = df_data[text_column].fillna(\"\").astype(str).tolist()"
      ],
      "metadata": {
        "id": "9z3iILI3K-vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Predict all texts ====\n",
        "results = clf(texts, batch_size=32, truncation=True)\n",
        "\n",
        "pred_labels = []\n",
        "max_scores = []\n",
        "neg_scores = []\n",
        "neu_scores = []\n",
        "pos_scores = []\n",
        "\n",
        "for item in results:\n",
        "    # item = list of dict: [{'label': 'negative', 'score': ...}, ...]\n",
        "    # choose the label with the highest score\n",
        "    best = max(item, key=lambda x: x[\"score\"])\n",
        "    pred_labels.append(best[\"label\"])     # 'negative' / 'neutral' / 'positive'\n",
        "    max_scores.append(best[\"score\"])\n",
        "\n",
        "    # take all the scores\n",
        "    score_dict = {d[\"label\"]: d[\"score\"] for d in item}\n",
        "    neg_scores.append(score_dict.get(\"negative\", None))\n",
        "    neu_scores.append(score_dict.get(\"neutral\", None))\n",
        "    pos_scores.append(score_dict.get(\"positive\", None))\n",
        "\n",
        "# ==== 5. Input the result to dataframe ====\n",
        "df_data[\"sentiment_label\"] = pred_labels          # negative / neutral / positive\n",
        "df_data[\"sentiment_confidence\"] = max_scores\n",
        "df_data[\"score_negative\"] = neg_scores\n",
        "df_data[\"score_neutral\"] = neu_scores\n",
        "df_data[\"score_positive\"] = pos_scores\n",
        "\n",
        "# Define OUTPUT_CSV_model2 before use\n",
        "OUTPUT_CSV_model2 = \"reviews_with_sentiment_model2.csv\"\n",
        "\n",
        "# ==== 6. Save in new csv file ====\n",
        "df_data.to_csv(OUTPUT_CSV_model2, index=False)\n",
        "print(f\"Done! Saved with sentiment to: {OUTPUT_CSV_model2}\")\n",
        "\n",
        "# ==== PIE CHART ====\n",
        "counts = df_data[\"sentiment_label\"].value_counts()\n",
        "\n",
        "plt.figure()\n",
        "plt.pie(\n",
        "    counts,\n",
        "    labels=[lbl.upper() for lbl in counts.index],  # POSITIVE / NEGATIVE / NEUTRAL\n",
        "    autopct=\"%1.1f%%\"\n",
        ")\n",
        "plt.title(\"Sentiment Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aXvSBrQzLYMn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}